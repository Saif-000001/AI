{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133fb60a-86a1-4eb8-aca0-f26cbf249f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 01:57:23.654675: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-26 01:57:23.654722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-26 01:57:23.655921: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-26 01:57:23.662427: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-26 01:57:24.442859: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6755bc2c-d01b-425b-99bf-1e716c72ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample Data\n",
    "celcius = np.array([-10, 0,60,62,64,66,68,70,72,74], dtype = float)\n",
    "fahrenheit = np.array([14,32,140, 143.6, 147.2, 150.8, 154.4, 158, 161.6, 165.2], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b19c776-2202-4f16-bb0a-c42667b141de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(units=4, input_shape=[1], activation='relu'),\n",
    "    layers.Dense(units=3, activation='relu'), \n",
    "    layers.Dense(units=1) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b69c0d9e-bdaf-4b3f-8233-e00eeb31cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss='mean_squared_error')\n",
    "# model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8543bf22-33d5-4369-9963-2bbd1bd6bf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 17277.0645\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16828.3789\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 16374.7686\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 15916.2715\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 15452.1855\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 14980.6406\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 14499.0752\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 14005.5811\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13499.4160\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12980.6523\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12449.7910\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11907.5879\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11354.9980\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10793.1377\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10223.2988\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9646.9551\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9065.7480\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8481.5020\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7896.2290\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7312.1274\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6731.5806\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6157.1572\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5591.6016\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5037.8140\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4498.8481\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3977.8911\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3478.1655\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3002.9509\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2555.5063\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2138.9956\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1756.4055\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1410.4412\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1103.4100\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 837.0928\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 612.6346\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 430.3224\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 289.4877\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 188.4419\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 124.3840\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 93.4050\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 90.5805\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 110.1609\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 145.8865\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 191.2859\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 240.1640\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 286.9978\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 327.2770\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 357.7409\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 376.4772\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 382.8992\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 377.5390\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 361.8554\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 337.9500\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 308.2032\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 275.0915\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 240.9402\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 207.7699\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 177.1942\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 150.3742\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 128.0210\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 110.4276\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 97.5327\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 88.9924\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 84.2584\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 82.6558\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 83.4511\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 85.9115\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 89.3513\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 93.1658\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 96.8535\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 100.0272\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 102.4163\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 103.8613\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 104.3034\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 103.7686\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 102.3516\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 100.1966\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 97.5090\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 94.4533\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 91.2161\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 87.9727\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 84.1235\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 78.3313\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 75.3774\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 76.5539\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 79.2338\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 79.9015\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 78.2513\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 75.6353\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 73.5058\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 72.7259\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 72.9984\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 72.6253\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 72.2407\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 71.8630\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 71.4855\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 71.0984\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 70.7027\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 70.2985\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 69.8855\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 69.4627\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 69.0293\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 68.5842\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 68.1353\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 67.6856\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 67.2230\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 66.7475\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 66.2595\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 65.7599\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 65.2495\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 64.7295\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 64.2008\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 63.6645\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 63.1216\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 62.5728\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 62.0305\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 61.4804\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 60.9199\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 60.3496\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 59.7815\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 59.2128\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 58.6384\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 58.0584\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 57.4726\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 56.8810\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 56.2836\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 55.6803\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 55.0713\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 54.4568\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 53.8369\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 53.2118\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 52.5903\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 51.9590\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 51.3156\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 50.6779\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 50.0364\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 49.3908\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 48.7413\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 48.0883\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 47.4321\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 46.7729\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 46.1111\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 45.4468\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 44.7804\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 44.1122\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 43.4424\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 42.7713\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 42.0992\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 41.4266\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 40.7609\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 40.0882\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 39.4127\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 38.7433\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 38.0746\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 37.4069\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 36.7405\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 36.0759\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 35.3642\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 34.0782\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 34.0416\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 32.9500\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 32.0952\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 31.2843\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 31.1720\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 29.6421\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 28.9969\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 28.3661\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 27.6927\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 27.3905\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 26.7751\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 25.9070\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 25.9083\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 25.5360\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 25.1385\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 24.7465\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 24.3595\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 23.9718\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 23.5844\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 23.1954\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 22.6752\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 22.1479\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 21.6283\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 21.4135\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 21.1926\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.7039\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 20.7573\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.5009\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 20.0649\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.2898\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6923\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.9258\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.5368\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.2572\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.4948\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.9248\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.1918\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.7946\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.7766\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.7121\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.4477\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.5433\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.2854\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.3668\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.1882\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.1873\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.1200\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.0331\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.0494\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.9226\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.9699\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.8903\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.8461\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.8565\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.7666\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.7736\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.7344\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.6986\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 17.6988\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.6406\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.6490\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.6008\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.5894\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.5789\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.5415\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.5184\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.5126\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.5002\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.4614\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.4653\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.4274\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.4172\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.3979\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.3685\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.3607\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.3276\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.3172\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.3435\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.2723\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.2903\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.3170\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.2159\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.2655\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.2007\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.1827\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.1877\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.1200\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.1411\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.0894\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.0819\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.1361\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.0239\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.0764\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.0797\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.9671\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.0404\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.9429\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.9511\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.9389\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.8717\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.9040\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.8311\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.8581\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.8678\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.7669\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.8395\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.7881\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.7231\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.7695\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.7057\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.6837\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.6966\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.6227\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.6524\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.5938\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.5849\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.5716\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.5241\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.5318\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.4830\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.4746\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.4617\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.4265\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.4009\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.4039\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.3856\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.3424\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.3467\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.3092\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.2939\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.2786\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 16.2441\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.2371\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.2096\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.1908\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 16.1642\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.1505\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.1272\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.1059\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.0974\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.0930\n"
     ]
    }
   ],
   "source": [
    "# train model \n",
    "history = model.fit(celcius, fahrenheit, epochs=300, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1d62295-180d-43d4-a9a6-76dc424a244b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300, Loss: 17277.0645\n",
      "Epoch 2/300, Loss: 16828.3789\n",
      "Epoch 3/300, Loss: 16374.7686\n",
      "Epoch 4/300, Loss: 15916.2715\n",
      "Epoch 5/300, Loss: 15452.1855\n",
      "Epoch 6/300, Loss: 14980.6406\n",
      "Epoch 7/300, Loss: 14499.0752\n",
      "Epoch 8/300, Loss: 14005.5811\n",
      "Epoch 9/300, Loss: 13499.4160\n",
      "Epoch 10/300, Loss: 12980.6523\n",
      "Epoch 11/300, Loss: 12449.7910\n",
      "Epoch 12/300, Loss: 11907.5879\n",
      "Epoch 13/300, Loss: 11354.9980\n",
      "Epoch 14/300, Loss: 10793.1377\n",
      "Epoch 15/300, Loss: 10223.2988\n",
      "Epoch 16/300, Loss: 9646.9551\n",
      "Epoch 17/300, Loss: 9065.7480\n",
      "Epoch 18/300, Loss: 8481.5020\n",
      "Epoch 19/300, Loss: 7896.2290\n",
      "Epoch 20/300, Loss: 7312.1274\n",
      "Epoch 21/300, Loss: 6731.5806\n",
      "Epoch 22/300, Loss: 6157.1572\n",
      "Epoch 23/300, Loss: 5591.6016\n",
      "Epoch 24/300, Loss: 5037.8140\n",
      "Epoch 25/300, Loss: 4498.8481\n",
      "Epoch 26/300, Loss: 3977.8911\n",
      "Epoch 27/300, Loss: 3478.1655\n",
      "Epoch 28/300, Loss: 3002.9509\n",
      "Epoch 29/300, Loss: 2555.5063\n",
      "Epoch 30/300, Loss: 2138.9956\n",
      "Epoch 31/300, Loss: 1756.4055\n",
      "Epoch 32/300, Loss: 1410.4412\n",
      "Epoch 33/300, Loss: 1103.4100\n",
      "Epoch 34/300, Loss: 837.0928\n",
      "Epoch 35/300, Loss: 612.6346\n",
      "Epoch 36/300, Loss: 430.3224\n",
      "Epoch 37/300, Loss: 289.4877\n",
      "Epoch 38/300, Loss: 188.4419\n",
      "Epoch 39/300, Loss: 124.3840\n",
      "Epoch 40/300, Loss: 93.4050\n",
      "Epoch 41/300, Loss: 90.5805\n",
      "Epoch 42/300, Loss: 110.1609\n",
      "Epoch 43/300, Loss: 145.8865\n",
      "Epoch 44/300, Loss: 191.2859\n",
      "Epoch 45/300, Loss: 240.1640\n",
      "Epoch 46/300, Loss: 286.9978\n",
      "Epoch 47/300, Loss: 327.2770\n",
      "Epoch 48/300, Loss: 357.7409\n",
      "Epoch 49/300, Loss: 376.4772\n",
      "Epoch 50/300, Loss: 382.8992\n",
      "Epoch 51/300, Loss: 377.5390\n",
      "Epoch 52/300, Loss: 361.8554\n",
      "Epoch 53/300, Loss: 337.9500\n",
      "Epoch 54/300, Loss: 308.2032\n",
      "Epoch 55/300, Loss: 275.0915\n",
      "Epoch 56/300, Loss: 240.9402\n",
      "Epoch 57/300, Loss: 207.7699\n",
      "Epoch 58/300, Loss: 177.1942\n",
      "Epoch 59/300, Loss: 150.3742\n",
      "Epoch 60/300, Loss: 128.0210\n",
      "Epoch 61/300, Loss: 110.4276\n",
      "Epoch 62/300, Loss: 97.5327\n",
      "Epoch 63/300, Loss: 88.9924\n",
      "Epoch 64/300, Loss: 84.2584\n",
      "Epoch 65/300, Loss: 82.6558\n",
      "Epoch 66/300, Loss: 83.4511\n",
      "Epoch 67/300, Loss: 85.9115\n",
      "Epoch 68/300, Loss: 89.3513\n",
      "Epoch 69/300, Loss: 93.1658\n",
      "Epoch 70/300, Loss: 96.8535\n",
      "Epoch 71/300, Loss: 100.0272\n",
      "Epoch 72/300, Loss: 102.4163\n",
      "Epoch 73/300, Loss: 103.8613\n",
      "Epoch 74/300, Loss: 104.3034\n",
      "Epoch 75/300, Loss: 103.7686\n",
      "Epoch 76/300, Loss: 102.3516\n",
      "Epoch 77/300, Loss: 100.1966\n",
      "Epoch 78/300, Loss: 97.5090\n",
      "Epoch 79/300, Loss: 94.4533\n",
      "Epoch 80/300, Loss: 91.2161\n",
      "Epoch 81/300, Loss: 87.9727\n",
      "Epoch 82/300, Loss: 84.1235\n",
      "Epoch 83/300, Loss: 78.3313\n",
      "Epoch 84/300, Loss: 75.3774\n",
      "Epoch 85/300, Loss: 76.5539\n",
      "Epoch 86/300, Loss: 79.2338\n",
      "Epoch 87/300, Loss: 79.9015\n",
      "Epoch 88/300, Loss: 78.2513\n",
      "Epoch 89/300, Loss: 75.6353\n",
      "Epoch 90/300, Loss: 73.5058\n",
      "Epoch 91/300, Loss: 72.7259\n",
      "Epoch 92/300, Loss: 72.9984\n",
      "Epoch 93/300, Loss: 72.6253\n",
      "Epoch 94/300, Loss: 72.2407\n",
      "Epoch 95/300, Loss: 71.8630\n",
      "Epoch 96/300, Loss: 71.4855\n",
      "Epoch 97/300, Loss: 71.0984\n",
      "Epoch 98/300, Loss: 70.7027\n",
      "Epoch 99/300, Loss: 70.2985\n",
      "Epoch 100/300, Loss: 69.8855\n",
      "Epoch 101/300, Loss: 69.4627\n",
      "Epoch 102/300, Loss: 69.0293\n",
      "Epoch 103/300, Loss: 68.5842\n",
      "Epoch 104/300, Loss: 68.1353\n",
      "Epoch 105/300, Loss: 67.6856\n",
      "Epoch 106/300, Loss: 67.2230\n",
      "Epoch 107/300, Loss: 66.7475\n",
      "Epoch 108/300, Loss: 66.2595\n",
      "Epoch 109/300, Loss: 65.7599\n",
      "Epoch 110/300, Loss: 65.2495\n",
      "Epoch 111/300, Loss: 64.7295\n",
      "Epoch 112/300, Loss: 64.2008\n",
      "Epoch 113/300, Loss: 63.6645\n",
      "Epoch 114/300, Loss: 63.1216\n",
      "Epoch 115/300, Loss: 62.5728\n",
      "Epoch 116/300, Loss: 62.0305\n",
      "Epoch 117/300, Loss: 61.4804\n",
      "Epoch 118/300, Loss: 60.9199\n",
      "Epoch 119/300, Loss: 60.3496\n",
      "Epoch 120/300, Loss: 59.7815\n",
      "Epoch 121/300, Loss: 59.2128\n",
      "Epoch 122/300, Loss: 58.6384\n",
      "Epoch 123/300, Loss: 58.0584\n",
      "Epoch 124/300, Loss: 57.4726\n",
      "Epoch 125/300, Loss: 56.8810\n",
      "Epoch 126/300, Loss: 56.2836\n",
      "Epoch 127/300, Loss: 55.6803\n",
      "Epoch 128/300, Loss: 55.0713\n",
      "Epoch 129/300, Loss: 54.4568\n",
      "Epoch 130/300, Loss: 53.8369\n",
      "Epoch 131/300, Loss: 53.2118\n",
      "Epoch 132/300, Loss: 52.5903\n",
      "Epoch 133/300, Loss: 51.9590\n",
      "Epoch 134/300, Loss: 51.3156\n",
      "Epoch 135/300, Loss: 50.6779\n",
      "Epoch 136/300, Loss: 50.0364\n",
      "Epoch 137/300, Loss: 49.3908\n",
      "Epoch 138/300, Loss: 48.7413\n",
      "Epoch 139/300, Loss: 48.0883\n",
      "Epoch 140/300, Loss: 47.4321\n",
      "Epoch 141/300, Loss: 46.7729\n",
      "Epoch 142/300, Loss: 46.1111\n",
      "Epoch 143/300, Loss: 45.4468\n",
      "Epoch 144/300, Loss: 44.7804\n",
      "Epoch 145/300, Loss: 44.1122\n",
      "Epoch 146/300, Loss: 43.4424\n",
      "Epoch 147/300, Loss: 42.7713\n",
      "Epoch 148/300, Loss: 42.0992\n",
      "Epoch 149/300, Loss: 41.4266\n",
      "Epoch 150/300, Loss: 40.7609\n",
      "Epoch 151/300, Loss: 40.0882\n",
      "Epoch 152/300, Loss: 39.4127\n",
      "Epoch 153/300, Loss: 38.7433\n",
      "Epoch 154/300, Loss: 38.0746\n",
      "Epoch 155/300, Loss: 37.4069\n",
      "Epoch 156/300, Loss: 36.7405\n",
      "Epoch 157/300, Loss: 36.0759\n",
      "Epoch 158/300, Loss: 35.3642\n",
      "Epoch 159/300, Loss: 34.0782\n",
      "Epoch 160/300, Loss: 34.0416\n",
      "Epoch 161/300, Loss: 32.9500\n",
      "Epoch 162/300, Loss: 32.0952\n",
      "Epoch 163/300, Loss: 31.2843\n",
      "Epoch 164/300, Loss: 31.1720\n",
      "Epoch 165/300, Loss: 29.6421\n",
      "Epoch 166/300, Loss: 28.9969\n",
      "Epoch 167/300, Loss: 28.3661\n",
      "Epoch 168/300, Loss: 27.6927\n",
      "Epoch 169/300, Loss: 27.3905\n",
      "Epoch 170/300, Loss: 26.7751\n",
      "Epoch 171/300, Loss: 25.9070\n",
      "Epoch 172/300, Loss: 25.9083\n",
      "Epoch 173/300, Loss: 25.5360\n",
      "Epoch 174/300, Loss: 25.1385\n",
      "Epoch 175/300, Loss: 24.7465\n",
      "Epoch 176/300, Loss: 24.3595\n",
      "Epoch 177/300, Loss: 23.9718\n",
      "Epoch 178/300, Loss: 23.5844\n",
      "Epoch 179/300, Loss: 23.1954\n",
      "Epoch 180/300, Loss: 22.6752\n",
      "Epoch 181/300, Loss: 22.1479\n",
      "Epoch 182/300, Loss: 21.6283\n",
      "Epoch 183/300, Loss: 21.4135\n",
      "Epoch 184/300, Loss: 21.1926\n",
      "Epoch 185/300, Loss: 20.7039\n",
      "Epoch 186/300, Loss: 20.7573\n",
      "Epoch 187/300, Loss: 20.5009\n",
      "Epoch 188/300, Loss: 20.0649\n",
      "Epoch 189/300, Loss: 20.2898\n",
      "Epoch 190/300, Loss: 19.6923\n",
      "Epoch 191/300, Loss: 19.9258\n",
      "Epoch 192/300, Loss: 19.5368\n",
      "Epoch 193/300, Loss: 19.2572\n",
      "Epoch 194/300, Loss: 19.4948\n",
      "Epoch 195/300, Loss: 18.9248\n",
      "Epoch 196/300, Loss: 19.1918\n",
      "Epoch 197/300, Loss: 18.7946\n",
      "Epoch 198/300, Loss: 18.7766\n",
      "Epoch 199/300, Loss: 18.7121\n",
      "Epoch 200/300, Loss: 18.4477\n",
      "Epoch 201/300, Loss: 18.5433\n",
      "Epoch 202/300, Loss: 18.2854\n",
      "Epoch 203/300, Loss: 18.3668\n",
      "Epoch 204/300, Loss: 18.1882\n",
      "Epoch 205/300, Loss: 18.1873\n",
      "Epoch 206/300, Loss: 18.1200\n",
      "Epoch 207/300, Loss: 18.0331\n",
      "Epoch 208/300, Loss: 18.0494\n",
      "Epoch 209/300, Loss: 17.9226\n",
      "Epoch 210/300, Loss: 17.9699\n",
      "Epoch 211/300, Loss: 17.8903\n",
      "Epoch 212/300, Loss: 17.8461\n",
      "Epoch 213/300, Loss: 17.8565\n",
      "Epoch 214/300, Loss: 17.7666\n",
      "Epoch 215/300, Loss: 17.7736\n",
      "Epoch 216/300, Loss: 17.7344\n",
      "Epoch 217/300, Loss: 17.6986\n",
      "Epoch 218/300, Loss: 17.6988\n",
      "Epoch 219/300, Loss: 17.6406\n",
      "Epoch 220/300, Loss: 17.6490\n",
      "Epoch 221/300, Loss: 17.6008\n",
      "Epoch 222/300, Loss: 17.5894\n",
      "Epoch 223/300, Loss: 17.5789\n",
      "Epoch 224/300, Loss: 17.5415\n",
      "Epoch 225/300, Loss: 17.5184\n",
      "Epoch 226/300, Loss: 17.5126\n",
      "Epoch 227/300, Loss: 17.5002\n",
      "Epoch 228/300, Loss: 17.4614\n",
      "Epoch 229/300, Loss: 17.4653\n",
      "Epoch 230/300, Loss: 17.4274\n",
      "Epoch 231/300, Loss: 17.4172\n",
      "Epoch 232/300, Loss: 17.3979\n",
      "Epoch 233/300, Loss: 17.3685\n",
      "Epoch 234/300, Loss: 17.3607\n",
      "Epoch 235/300, Loss: 17.3276\n",
      "Epoch 236/300, Loss: 17.3172\n",
      "Epoch 237/300, Loss: 17.3435\n",
      "Epoch 238/300, Loss: 17.2723\n",
      "Epoch 239/300, Loss: 17.2903\n",
      "Epoch 240/300, Loss: 17.3170\n",
      "Epoch 241/300, Loss: 17.2159\n",
      "Epoch 242/300, Loss: 17.2655\n",
      "Epoch 243/300, Loss: 17.2007\n",
      "Epoch 244/300, Loss: 17.1827\n",
      "Epoch 245/300, Loss: 17.1877\n",
      "Epoch 246/300, Loss: 17.1200\n",
      "Epoch 247/300, Loss: 17.1411\n",
      "Epoch 248/300, Loss: 17.0894\n",
      "Epoch 249/300, Loss: 17.0819\n",
      "Epoch 250/300, Loss: 17.1361\n",
      "Epoch 251/300, Loss: 17.0239\n",
      "Epoch 252/300, Loss: 17.0764\n",
      "Epoch 253/300, Loss: 17.0797\n",
      "Epoch 254/300, Loss: 16.9671\n",
      "Epoch 255/300, Loss: 17.0404\n",
      "Epoch 256/300, Loss: 16.9429\n",
      "Epoch 257/300, Loss: 16.9511\n",
      "Epoch 258/300, Loss: 16.9389\n",
      "Epoch 259/300, Loss: 16.8717\n",
      "Epoch 260/300, Loss: 16.9040\n",
      "Epoch 261/300, Loss: 16.8311\n",
      "Epoch 262/300, Loss: 16.8581\n",
      "Epoch 263/300, Loss: 16.8678\n",
      "Epoch 264/300, Loss: 16.7669\n",
      "Epoch 265/300, Loss: 16.8395\n",
      "Epoch 266/300, Loss: 16.7881\n",
      "Epoch 267/300, Loss: 16.7231\n",
      "Epoch 268/300, Loss: 16.7695\n",
      "Epoch 269/300, Loss: 16.7057\n",
      "Epoch 270/300, Loss: 16.6837\n",
      "Epoch 271/300, Loss: 16.6966\n",
      "Epoch 272/300, Loss: 16.6227\n",
      "Epoch 273/300, Loss: 16.6524\n",
      "Epoch 274/300, Loss: 16.5938\n",
      "Epoch 275/300, Loss: 16.5849\n",
      "Epoch 276/300, Loss: 16.5716\n",
      "Epoch 277/300, Loss: 16.5241\n",
      "Epoch 278/300, Loss: 16.5318\n",
      "Epoch 279/300, Loss: 16.4830\n",
      "Epoch 280/300, Loss: 16.4746\n",
      "Epoch 281/300, Loss: 16.4617\n",
      "Epoch 282/300, Loss: 16.4265\n",
      "Epoch 283/300, Loss: 16.4009\n",
      "Epoch 284/300, Loss: 16.4039\n",
      "Epoch 285/300, Loss: 16.3856\n",
      "Epoch 286/300, Loss: 16.3424\n",
      "Epoch 287/300, Loss: 16.3467\n",
      "Epoch 288/300, Loss: 16.3092\n",
      "Epoch 289/300, Loss: 16.2939\n",
      "Epoch 290/300, Loss: 16.2786\n",
      "Epoch 291/300, Loss: 16.2441\n",
      "Epoch 292/300, Loss: 16.2371\n",
      "Epoch 293/300, Loss: 16.2096\n",
      "Epoch 294/300, Loss: 16.1908\n",
      "Epoch 295/300, Loss: 16.1642\n",
      "Epoch 296/300, Loss: 16.1505\n",
      "Epoch 297/300, Loss: 16.1272\n",
      "Epoch 298/300, Loss: 16.1059\n",
      "Epoch 299/300, Loss: 16.0974\n",
      "Epoch 300/300, Loss: 16.0930\n"
     ]
    }
   ],
   "source": [
    "for epoch, loss in enumerate(history.history['loss']):\n",
    "    print(f\"Epoch {epoch+1}/{300}, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c8372f6-2540-4e12-a8a4-b8e23434f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_celcius = [61,63,65,67,69]\n",
    "new_fahrenheit = [141.8,145.4,149,152.6,156.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30e29a09-2c81-4ab2-b009-e829c7981efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    }
   ],
   "source": [
    "celcius_test = np.array(new_celcius, dtype = float)\n",
    "new_tamperture_predict = model.predict(celcius_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04707661-fb7c-46ad-a2e7-50a0528a833c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 61 True temperature:141.80, Predicted temperature: 141.02 \n",
      "Data: 63 True temperature:145.40, Predicted temperature: 144.90 \n",
      "Data: 65 True temperature:149.00, Predicted temperature: 148.79 \n",
      "Data: 67 True temperature:152.60, Predicted temperature: 152.67 \n",
      "Data: 69 True temperature:156.20, Predicted temperature: 156.55 \n"
     ]
    }
   ],
   "source": [
    "# prediction output\n",
    "for n_d, n_t_f, n_t_p in zip(new_celcius, new_fahrenheit, new_tamperture_predict):\n",
    "    print(f\"Data: {n_d} True temperature:{n_t_f:.2f}, Predicted temperature: {n_t_p[0]:.2f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8004249b-63cb-424d-bed2-830396c6ca05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
